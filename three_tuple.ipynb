{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import gensim\n",
    "import numpy\n",
    "import jieba\n",
    "import collections\n",
    "from sklearn import metrics\n",
    "from gensim.models import word2vec\n",
    "from sklearn.cluster import KMeans\n",
    "from openpyxl.workbook import Workbook\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68288\n"
     ]
    }
   ],
   "source": [
    "f = open(r\"E:\\高中低\\标注结果\\crf_result-low.txt\",encoding='utf-8')\n",
    "text = f.readlines()\n",
    "countt = 1\n",
    "cut = []\n",
    "for j in text:\n",
    "    if (j==\" \\n\"):\n",
    "        countt+=1      #将word与tag分开                \n",
    "print(countt)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import xrange\n",
    "text100 = []\n",
    "Text100 = []\n",
    "emotion_pairs = []\n",
    "##\n",
    "for i in xrange(countt):       ##\n",
    "    text100.append([])\n",
    "    Text100.append([])\n",
    "    emotion_pairs.append([])\n",
    "count = 0\n",
    "for j in text:\n",
    "    if (j!=' \\n'):         \n",
    "        text100[count].append(j[:-1].split(\" \"))      #将word与tag分开                \n",
    "    else:\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = []\n",
    "for i,y in enumerate(text100):\n",
    "    l = 1\n",
    "    for j,yy in enumerate(y):\n",
    "        if(j!=(len(y)-1)):\n",
    "            if((yy[0]==\",\") or (yy[0]==\"，\") or (yy[0]==\"！\") or (yy[0]==\"!\") or (yy[0]==\"。\") or (yy[0]==\".\") or (yy[0]==\"？\") or (yy[0]==\"?\")):\n",
    "                l+=1\n",
    "    cut.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(countt):    ###\n",
    "    for j in xrange(cut[i]):\n",
    "        emotion_pairs[i].append({'属性词':[],'情感词':[],'修饰词':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "Count = 0\n",
    "#t = text[331]\n",
    "for j in text:\n",
    "#     if(Count%100000==0):\n",
    "#         print(Count)\n",
    "    if (j!=' \\n'):         \n",
    "        if((j[:-1].split(\" \")[0]!=\",\") and (j[:-1].split(\" \")[0]!=\"，\") and (j[:-1].split(\" \")[0]!=\"！\") and (j[:-1].split(\" \")[0]!=\"!\") and (j[:-1].split(\" \")[0]!=\"。\") and (j[:-1].split(\" \")[0]!=\".\") and (j[:-1].split(\" \")[0]!=\"？\") and (j[:-1].split(\" \")[0]!=\"?\")):\n",
    "            list1.append(j[:-1].split(\" \"))\n",
    "        else:\n",
    "            Text100[Count].append(list1)      #将word与tag分开     \n",
    "            list1 = []\n",
    "    else:\n",
    "        if(len(Text100[Count])!=cut[Count]):\n",
    "            Text100[Count].append(list1)\n",
    "            list1 = []\n",
    "        Count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,y1 in enumerate(Text100):\n",
    "#     if(i%50000==0):\n",
    "#         print(i)\n",
    "    for j,y2 in enumerate(y1):\n",
    "        a = ''\n",
    "        b = ''\n",
    "        c = ''\n",
    "        counta = 1\n",
    "        countb = 1\n",
    "        countc = 1\n",
    "        for k,y3 in enumerate(y2):\n",
    "#             print(y3)\n",
    "            if(y3[1]=='S-attribute'):\n",
    "                if(len(emotion_pairs[i][j]['属性词'])>0):\n",
    "                    emotion_pairs[i][j]['属性词'].append(str(counta+1)+\"-\"+y3[0])\n",
    "                else:\n",
    "                    emotion_pairs[i][j]['属性词'].append(str(counta)+\"-\"+y3[0])\n",
    "            elif(y3[1]=='S-embellish'):\n",
    "                b = b+y3[0]\n",
    "                if(len(emotion_pairs[i][j]['修饰词'])>0):\n",
    "                    if((k+1)<len(y2)):\n",
    "                        if((y2[k+1][1]=='B-embellish') or (y2[k+1][1]=='S-embellish')):\n",
    "                            b = b+\"+\"\n",
    "                        else:\n",
    "                            emotion_pairs[i][j]['修饰词'].append(str(countb+1)+\"-\"+b)\n",
    "                            b = ''\n",
    "                    else:\n",
    "                        emotion_pairs[i][j]['修饰词'].append(str(countb+1)+\"-\"+b)\n",
    "                        b = ''\n",
    "                else:\n",
    "                    if((k+1)<len(y2)):\n",
    "                        if((y2[k+1][1]=='B-embellish') or (y2[k+1][1]=='S-embellish')):\n",
    "                            b = b+\"+\"\n",
    "                        else:\n",
    "                            emotion_pairs[i][j]['修饰词'].append(str(countb)+\"-\"+b)\n",
    "                            b = ''\n",
    "                    else:\n",
    "                        emotion_pairs[i][j]['修饰词'].append(str(countb)+\"-\"+b)\n",
    "                        b = ''\n",
    "            elif(y3[1]=='S-emotion'):\n",
    "                if(len(emotion_pairs[i][j]['情感词'])>0):\n",
    "                    emotion_pairs[i][j]['情感词'].append(str(countc+1)+\"-\"+y3[0])\n",
    "                else:\n",
    "                    emotion_pairs[i][j]['情感词'].append(str(countc)+\"-\"+y3[0])\n",
    "            elif(y3[1]=='B-attribute'):\n",
    "                a = a+y3[0]\n",
    "            elif(y3[1]=='I-attribute'):\n",
    "                a = a+y3[0]\n",
    "            elif(y3[1]=='E-attribute'):\n",
    "                a = a+y3[0]\n",
    "                if(len(emotion_pairs[i][j]['属性词'])>0):\n",
    "                    emotion_pairs[i][j]['属性词'].append(str(counta+1)+\"-\"+a)\n",
    "                else:\n",
    "                    emotion_pairs[i][j]['属性词'].append(str(counta)+\"-\"+a)\n",
    "                a = ''\n",
    "            elif(y3[1]=='B-embellish'):\n",
    "                b = b+y3[0]\n",
    "            elif(y3[1]=='I-embellish'):\n",
    "                b = b+y3[0]\n",
    "            elif(y3[1]=='E-embellish'):\n",
    "                b = b+y3[0]\n",
    "                if(len(emotion_pairs[i][j]['修饰词'])>0):\n",
    "                    if((k+1)<len(y2)):\n",
    "                        if((y2[k+1][1]=='B-embellish') or (y2[k+1][1]=='S-embellish')):\n",
    "                            b = b+\"+\"\n",
    "                        else:\n",
    "                            emotion_pairs[i][j]['修饰词'].append(str(countb+1)+\"-\"+b)\n",
    "                            b = ''\n",
    "                    else:\n",
    "                        emotion_pairs[i][j]['修饰词'].append(str(countb+1)+\"-\"+b)\n",
    "                        b = ''\n",
    "                else:\n",
    "                    if((k+1)<len(y2)):\n",
    "                        if((y2[k+1][1]=='B-embellish') or (y2[k+1][1]=='S-embellish')):\n",
    "                            b = b+\"+\"\n",
    "                        else:\n",
    "                            emotion_pairs[i][j]['修饰词'].append(str(countb)+\"-\"+b)\n",
    "                            b = ''\n",
    "                    else:\n",
    "                        emotion_pairs[i][j]['修饰词'].append(str(countb)+\"-\"+b)\n",
    "                        b = ''\n",
    "            elif(y3[1]=='B-emotion'):\n",
    "                c = c+y3[0]\n",
    "            elif(y3[1]=='I-emotion'):\n",
    "                c = c+y3[0]\n",
    "            elif(y3[1]=='E-emotion'):\n",
    "                c = c+y3[0]\n",
    "                if(len(emotion_pairs[i][j]['情感词'])>0):\n",
    "                    emotion_pairs[i][j]['情感词'].append(str(countc+1)+\"-\"+c)\n",
    "                else:\n",
    "                    emotion_pairs[i][j]['情感词'].append(str(countc)+\"-\"+c)\n",
    "                c = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#识别并列关系\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    if(i%100000==0):\n",
    "        print(i)\n",
    "    for j,y2 in enumerate(y1):\n",
    "        if((len(y2['属性词'])<=1) and (len(y2['情感词'])<=1) and (len(y2['修饰词'])<=1)):     #三者都为单个\n",
    "            new1 = []\n",
    "            if((str(y2['属性词']))[2:-2].split(\"-\")[-1]!=''):\n",
    "                new1.append((str(y2['属性词']))[2:-2].split(\"-\")[-1])\n",
    "            y2['属性词']=new1\n",
    "            new2 = []\n",
    "            if((str(y2['情感词']))[2:-2].split(\"-\")[-1]!=''):\n",
    "                new2.append((str(y2['情感词']))[2:-2].split(\"-\")[-1])\n",
    "            y2['情感词']=new2\n",
    "            new3 = []\n",
    "            if((str(y2['修饰词']))[2:-2].split(\"-\")[-1]!=''):\n",
    "                new3.append((str(y2['修饰词']))[2:-2].split(\"-\")[-1])\n",
    "            y2['修饰词']=new3\n",
    "        if((len(y2['属性词'])>1) and (len(y2['情感词'])<=1) and (len(y2['修饰词'])<=1)):     #属性词>1 and 修饰词<1\n",
    "            co1 = 0\n",
    "            for i1 in range((len(y2['属性词'])-1)): \n",
    "                if((len(y2['情感词'])!=0)):\n",
    "#                     str((int(y2['情感词'][col].split(\"-\")[0])+1))+\"-\"+(y2['情感词'][col].split(\"-\")[1])\n",
    "                    y2['情感词'].append(str((int(y2['情感词'][co1].split(\"-\")[0])+1))+\"-\"+(y2['情感词'][0].split(\"-\")[1]))\n",
    "                if(len(y2['修饰词'])!=0):\n",
    "                    y2['修饰词'].append(str((int(y2['修饰词'][co1].split(\"-\")[0])+1))+\"-\"+(y2['修饰词'][0].split(\"-\")[1]))\n",
    "                co1+=1\n",
    "        if((len(y2['属性词'])>1) and (len(y2['情感词'])<=1) and (len(y2['修饰词'])>1)):      #属性词>1 and 修饰词>1\n",
    "            co2 = 0\n",
    "            for i1 in range((len(y2['属性词'])-1)): \n",
    "                if(len(y2['情感词'])!=0):\n",
    "                    y2['情感词'].append(str((int(y2['情感词'][co2].split(\"-\")[0])+1))+\"-\"+(y2['情感词'][0].split(\"-\")[1]))\n",
    "                    co2+=1\n",
    "        if((len(y2['属性词'])<=1) and (len(y2['情感词'])>1)):      #情感词>1\n",
    "            co3 = 0\n",
    "            for i1 in range((len(y2['情感词'])-1)): \n",
    "                if(len(y2['属性词'])!=0):\n",
    "                    y2['属性词'].append(str((int(y2['属性词'][co3].split(\"-\")[0])+1))+\"-\"+(y2['属性词'][0].split(\"-\")[1]))\n",
    "                    co3+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割字典中列表\n",
    "for ii,y1 in enumerate(emotion_pairs):\n",
    "    dele = []\n",
    "    for j,y2 in enumerate(y1):\n",
    "        if((len(y2['属性词'])>1) or (len(y2['情感词'])>1) or (len(y2['修饰词'])>1)):\n",
    "            d_list = []\n",
    "            for q in range(max(len(y2['属性词']),len(y2['情感词']),len(y2['修饰词']))):\n",
    "                d_list.append({'属性词':[],'情感词':[],'修饰词':[]})\n",
    "            c1 = 1\n",
    "            for i in range(max(len(y2['属性词']),len(y2['情感词']),len(y2['修饰词']))):\n",
    "                if((len(y2['属性词'])!=0) and (i<len(y2['属性词']))):\n",
    "                    if(int(y2['属性词'][i].split(\"-\")[0])==c1):\n",
    "                        l1 = []\n",
    "                        l1.append(y2['属性词'][i].split(\"-\")[1])\n",
    "                        d_list[c1-1]['属性词']=l1\n",
    "                if((len(y2['情感词'])!=0) and (i<len(y2['情感词']))):\n",
    "                    if(int(y2['情感词'][i].split(\"-\")[0])==c1):\n",
    "                        l2 = []\n",
    "                        l2.append(y2['情感词'][i].split(\"-\")[1])\n",
    "                        d_list[c1-1]['情感词']=l2\n",
    "                if((len(y2['修饰词'])!=0) and (i<len(y2['修饰词']))):\n",
    "                    if(int(y2['修饰词'][i].split(\"-\")[0])==c1):\n",
    "                        l3 = []\n",
    "                        l3.append(y2['修饰词'][i].split(\"-\")[1])\n",
    "                        d_list[c1-1]['修饰词']=l3\n",
    "                c1+=1\n",
    "            for line in d_list:\n",
    "                emotion_pairs[ii].append(line)\n",
    "            dele.append(j)\n",
    "    for d in dele[::-1]:\n",
    "        del emotion_pairs[ii][d]\n",
    "\n",
    "#检验结果\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        if((len(y2['属性词'])>1) or (len(y2['情感词'])>1) or (len(y2['修饰词'])>1)):\n",
    "            print(i)\n",
    "            print(j)\n",
    "            print(\"----\")\n",
    "#处理修饰词\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        for k in y2['修饰词']:\n",
    "            if(\"+\" in k):\n",
    "                y2['修饰词']=(k.split(\"+\"))\n",
    "#删除空字典\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    DELE = []\n",
    "    for j,y2 in enumerate(y1):\n",
    "        if((len(y2['属性词'])==0) and (len(y2['情感词'])==0) and (len(y2['修饰词'])==0)):\n",
    "            DELE.append(j)\n",
    "    for D in DELE[::-1]:\n",
    "        del emotion_pairs[i][D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隐式属性\n",
    "q_list1=['便宜','划算','实惠','贵','优惠','不贵','物超所值','经济','涨价']#价格\n",
    "q_list2=['便利','便捷','方便']#交通\n",
    "q_list3=['干净','脏','舒适','舒服','潮湿','宽敞','明亮','干净利落','潮','暗','昏暗','漏水','反味','难闻','发霉']#环境\n",
    "q_list4=['齐全','旧','陈旧','新','老旧','破旧']#设施\n",
    "q_list5=['热情','贴心','耐心','友善','冷漠','体贴','亲切','周到','细心','细致','和蔼']#服务\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        if((len(y2['属性词'])==0) & (len(y2['情感词'])!=0)):\n",
    "            if(y2['情感词'][0] in q_list1):\n",
    "                y2['属性词'].append(\"价格\")\n",
    "            if(y2['情感词'][0] in q_list2):\n",
    "                y2['属性词'].append(\"交通\")\n",
    "            if(y2['情感词'][0] in q_list3):\n",
    "                y2['属性词'].append(\"环境\")\n",
    "            if(y2['情感词'][0] in q_list4):\n",
    "                y2['属性词'].append(\"设施\")\n",
    "            if(y2['情感词'][0] in q_list5):\n",
    "                y2['属性词'].append(\"服务\")\n",
    "# print(emotion_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "import json\n",
    "with open(r'E:\\高中低\\三元组\\triples-low.json','w',encoding = 'utf-8') as file:\n",
    "    file.write(json.dumps(emotion_pairs,indent = 2,ensure_ascii = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
