{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e351059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gensim\n",
    "import numpy as np\n",
    "import jieba\n",
    "import collections\n",
    "from gensim.models import word2vec\n",
    "from sklearn.cluster import KMeans\n",
    "from openpyxl.workbook import Workbook\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580a75d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: sklearn-cluster\n"
     ]
    }
   ],
   "source": [
    "pip show sklearn-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d31726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openpyxl\n",
      "Version: 3.0.9\n",
      "Summary: A Python library to read/write Excel 2010 xlsx/xlsm files\n",
      "Home-page: https://openpyxl.readthedocs.io\n",
      "Author: See AUTHORS\n",
      "Author-email: charlie.clark@clark-consulting.eu\n",
      "License: MIT\n",
      "Location: c:\\users\\11874\\anaconda3\\lib\\site-packages\n",
      "Requires: et-xmlfile\n",
      "Required-by: Orange3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555633c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: jieba\n",
      "Version: 0.42.1\n",
      "Summary: Chinese Words Segmentation Utilities\n",
      "Home-page: https://github.com/fxsjy/jieba\n",
      "Author: Sun, Junyi\n",
      "Author-email: ccnusjy@gmail.com\n",
      "License: MIT\n",
      "Location: c:\\users\\11874\\anaconda3\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "918f3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r'E:\\13wTDI数据\\高中低\\三元组\\triples-low.json','r',encoding='utf-8')as fp:\n",
    "    emotion_pairs = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e266b0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68288\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(len(emotion_pairs))\n",
    "print(emotion_pairs[len(emotion_pairs)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "325243d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68287\n"
     ]
    }
   ],
   "source": [
    "del(emotion_pairs[len(emotion_pairs)-1])\n",
    "print(len(emotion_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3588d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"E:\\13w聚类结果\\ordered2.csv\"\n",
    "with open(path, 'r', encoding = 'gbk') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    rows = [row for row in reader]\n",
    "    \n",
    "for c in rows:\n",
    "    while '' in c:\n",
    "        c.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd092fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['1', '服务', '服务态度', '用户已', '态度', '服务人员', '前台', '服务员', '工作人员', '推荐', '配套', '打扫', '前台态度', '管理', '前台接待', '服务质量', '服务设施', '素质', '用户', '服务环境', '服務', '员工', '接待', '效率', '客服', '整体服务', '真心', '服务意识', '阿姨', '前台人员', '办事', '服务生', '接送机', '速度', '客户', '时间', '姑娘', '服務態度', '办理', '客服态度', '退房', '办理入住', '清洁', '前台接待态度', '客服人员', '领导', '服务细节', '入住手续', '前台接待人员', '升级', '服务效率', '服务生态度', '办理速度', '客房服务', '服务水平', '前台效率', '接送', '送机', '带孩子', '总体服务', '接机', '办事效率', '办理手续', '感到', '卫生管理', '客服人员态度', '防疫措施', '入住效率', '前台员工', '员工态度', '进出', '保洁', '態度', '服务管理', '客户体验', '入住的', '业务', '商务人士', '接待人员', '消毒', '办理的速度', '工作态度', '阿姨态度', '维护', '手续', '自动化程度', '管理水平', '送餐', '人员', '实施', '服务优质', '行李', '前台小妹', '机场接送', '店', '查房', '大方', '员工素质', '服务速度', '保洁人员', '服务体验', '接送机师傅', '安全措施', '服务素质', '管理人员', '升级房型', '前台速度', '客户反馈', '换了房型', 'OK', '平台', '吵闹', '前台人', '保安', '安保措施', '入住流程', '服务台态度', '整体服务态度', '前台素质', '笑容', '待客', '总台服务', '治安', '客户说', '携程', '推介', '保洁员', '服务器', '语气', '年纪', '清理', '公司', '店员', '交流', '拿行李', '保安态度', '服务设置', '总台服务员', '办理业务', '前台妹妹', '推广', '女生', '服务品质', '大堂接待', '前台接待员', '工作效率', '接机司机', '体检', '服务接待', '环节', '客房服务态度', '保洁服务', '前台服务', '解决', '体贴', '操作', '办理时间', '素养', '维景', '客气', '客房服务员', '前台服务生', '出租车司机', '安全保障', '消毒措施', '管理员', '等候时间', '安保', '退房速度', '接机送机', '措施', '亲切感', '接待员', '服务均', '眼神', '解释', '服好', '防护', '性格', '待遇', '发票', '老板', '办理入住手续', '防护措施', '阿姨人', '服务水准', '客户入住', '寄存', '服务员效率', '能力', '整理', '客房人员', '工作人员效率', '清洁员', '前台工作人员', '押金', '酒店人员', '办理入住效率', '客人', '保护', '观光', '管理规范', '施舍', '暖心', '前台服务意识', '服务配套', '服务更', '制度', '等待时间', '人品', '相聚', '大堂工作人员', '清扫', '快速', '柜台人员', '办理退房', '卫生收拾', '安保人员', '清洁人员', '前台妹子', '负责', '安全方面', '接送车', '卫士', '沟通', '入住态度', '提示气质', '办事情', '妹妹', '客房服务人员', '服务费', '问候', '入住人员', '设立', '防控', '办理登记', '太度', '客流', '善良', '咨询', '电话', '帮忙', '业务能力', '换了间', '高效', '保养', '保安人员', '行政待遇', '防控措施', '信赖', '微笑', '升级房', '好评', '大堂人员', '眼力', '分工', '开口', '处理态度', '阿姨们', '小妹妹', '证件', '退房手续', '前台小妹妹', '防疫工作', '帅气']\n"
     ]
    }
   ],
   "source": [
    "print(len(rows))\n",
    "print(rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ad63abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in rows:\n",
    "    del c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "599b05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "def open_dict(Dict='hahah',path='D:/kmeans/kmeans聚类数据及代码/词典/'):\n",
    "    path = path + '%s.txt' %Dict\n",
    "    dictionary = open(path, 'r', encoding='utf-8-sig',errors='ignore')\n",
    "    dict = []\n",
    "    for word in dictionary:\n",
    "        word=word.strip('\\n')\n",
    "        word=word.strip(' ')\n",
    "        dict.append(word)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "08c8c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "posdict = open_dict(Dict='posdict')#积极情感词典\n",
    "negdict = open_dict(Dict='negdict')#消极情感词典\n",
    "inversedict = open_dict(Dict='inversedict')  #修饰词典，同下\n",
    "mostdict = open_dict(Dict='mostdict')\n",
    "verydict= open_dict(Dict='verydict')\n",
    "moredict = open_dict(Dict='moredict')\n",
    "ishdict = open_dict(Dict='ishdict')\n",
    "insufficientdict = open_dict(Dict='insufficientdict')\n",
    "\n",
    "f=open(r'D:\\kmeans\\kmeans聚类数据及代码\\词典\\酒店情感词典.txt','r',encoding='utf-8')\n",
    "words = []\n",
    "value=[]\n",
    "for word in f.readlines():\n",
    "    words.append(word.split(' ')[0])\n",
    "    value.append(float(word.split(' ')[1].strip('\\n')))\n",
    "\n",
    "c={'words':words,\n",
    "   'value':value}\n",
    "fd=pd.DataFrame(c)\n",
    "pos=fd['words'][fd.value>0]\n",
    "posdict=posdict+list(pos)    ##加入酒店相关的正向情感词\n",
    "neg=fd['words'][fd.value<0]\n",
    "negdict=negdict+list(neg)    ##加入酒店相关的负向情感词\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "80aca112",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr1 = open(r'D:\\kmeans\\评论情感个数\\pos.txt', 'r', encoding='utf-8') \n",
    "P = []\n",
    "for line in fr1:\n",
    "    P.append(line.strip())\n",
    "fr1.close()\n",
    "\n",
    "fr2 = open(r'D:\\kmeans\\评论情感个数\\neg.txt', 'r', encoding='utf-8') \n",
    "N = []\n",
    "for line in fr2:\n",
    "    N.append(line.strip())\n",
    "fr2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d91458bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_inverse(xiu_ci):   ###判断修饰词列表中否定词的个数\n",
    "    a = 0\n",
    "    for i in xiu_ci:\n",
    "        if i in inversedict:\n",
    "            a += 1\n",
    "    return a\n",
    "\n",
    "def get_intensity(xiu_ci):  ###获取修饰词强度的列表\n",
    "    intensity_list = []\n",
    "    for i in xiu_ci:\n",
    "        if(i in inversedict):\n",
    "            intensity_list.append(-1)\n",
    "        elif(i in mostdict):\n",
    "            intensity_list.append(2)\n",
    "        elif(i in verydict):\n",
    "            intensity_list.append(1.5)\n",
    "        elif(i in moredict):\n",
    "            intensity_list.append(1.2)\n",
    "        elif(i in ishdict):\n",
    "            intensity_list.append(0.8)\n",
    "        elif(i in insufficientdict):\n",
    "            intensity_list.append(0.5)\n",
    "        else:\n",
    "            intensity_list.append(1)    #修饰词不在目前的修饰词表中,赋值1\n",
    "    return intensity_list\n",
    "\n",
    "def add_xiu(xiu_ci):    #修饰词的情感强度计算（修饰词包含 强度>0的程度副词和强度=0的否定词）\n",
    "    v = 1\n",
    "    if(len(xiu_ci)==1):    #1 如果三元组中只有一个修饰词，则直接取该修饰词的强度；\n",
    "        for i in xiu_ci:\n",
    "            if(i in inversedict):\n",
    "                v = v*(-1)\n",
    "            elif(i in mostdict):\n",
    "                v = v*2\n",
    "            elif(i in verydict):\n",
    "                v = v*1.5\n",
    "            elif(i in moredict):\n",
    "                v = v*1.2\n",
    "            elif(i in ishdict):\n",
    "                v = v*0.8\n",
    "            elif(i in insufficientdict):\n",
    "                v = v*0.5\n",
    "    elif(len(xiu_ci)>1):      #2 如果三元组中出现多个修饰词，首先判断程度副词个数\n",
    "        if((len(xiu_ci)-is_inverse(xiu_ci))==0):     #2.1 程度副词个数=0，表明全为否定词，强度取 (-1)^否定词个数\n",
    "            v = (-1)**len(xiu_ci)    ##次方运算**\n",
    "        elif((len(xiu_ci)-is_inverse(xiu_ci))==1):    #2.2 程度副词个数=1\n",
    "            if(xiu_ci[0] in inversedict):     #2.2.1第一个修饰词为否定词,强度取 (-1)^否定词个数*修饰词的倒数\n",
    "                for i in xiu_ci[1:]:\n",
    "                    if i in mostdict:\n",
    "                        v = v*1/2\n",
    "                    elif i in verydict:\n",
    "                        v = v*1/1.5\n",
    "                    elif i in moredict:\n",
    "                        v = v*1/1.2\n",
    "                    elif i in ishdict:\n",
    "                        v = v*1/0.8\n",
    "                    elif i in insufficientdict:\n",
    "                        v = v*1/0.5\n",
    "                v = v*((-1)**is_inverse(xiu_ci))\n",
    "            else:                            #2.2.2 第一个修饰词不为否定词,强度取 (-1)^否定词个数*修饰词\n",
    "                for i in xiu_ci:\n",
    "                    if i in inversedict:\n",
    "                        v = v*(-1)\n",
    "                    elif i in mostdict:\n",
    "                        v = v*2\n",
    "                    elif i in verydict:\n",
    "                        v = v*1.5\n",
    "                    elif i in moredict:\n",
    "                        v = v*1.2\n",
    "                    elif i in ishdict:\n",
    "                        v = v*0.8\n",
    "                    elif i in insufficientdict:\n",
    "                        v = v*0.5\n",
    "        elif((len(xiu_ci)-is_inverse(xiu_ci))>1):    #2.3 程度副词个数>1\n",
    "            if(xiu_ci[0] in inversedict):     #2.3.1第一个修饰词为否定词,强度取 (-1)^否定词个数*修饰词的倒数中最大值*0.8\n",
    "                v = ((-1)**is_inverse(xiu_ci))*max([1/i for i in get_intensity(xiu_ci)])*0.8\n",
    "            else:                            #2.3.2 第一个修饰词不为否定词,强度取 (-1)^否定词个数*修饰词中最大值*1.8\n",
    "                v = ((-1)**is_inverse(xiu_ci))*max(get_intensity(xiu_ci))*1.8\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "838e8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[0].strip('\\ufeff')\n",
    "words.append('涨')   ## 自定义有关价格\"涨\"的情感值\n",
    "value.append(-0.591413615807158)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a827f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e654433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_value = []    ##三元组情感值\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    emotion_value.append([])\n",
    "    \n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        emotion_value[i].append(0)#每条三元组数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "384a974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68287\n"
     ]
    }
   ],
   "source": [
    "print(len(emotion_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "983e0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qingxiang(li):    ##情感倾向\n",
    "    v = 1\n",
    "    if((li in negdict) | (li in N)):\n",
    "        v = -1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "15d63f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_qg = dict(zip(words,value))#字典\n",
    "uncertain = []\n",
    "\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        if(len(y2['属性词'])!= 0):\n",
    "            if((len(y2['情感词'])!=0) or (len(y2['修饰词'])!=0)):\n",
    "                if(len(y2['情感词'])!= 0):\n",
    "                    emotion_value[i][j]=format(qingxiang(y2['情感词'][0])*(add_xiu(y2['修饰词'])), '.2f')#保留小数位，可更改\n",
    "                else:\n",
    "                    emotion_value[i][j]=format(add_xiu(y2['修饰词']), '.2f')#无情感词\n",
    "            \n",
    "for i,y1 in enumerate(emotion_value):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        try:\n",
    "            emotion_value[i][j]=eval(emotion_value[i][j])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31236617",
   "metadata": {},
   "outputs": [],
   "source": [
    "qg = []    #个数\n",
    "for i in range(len(emotion_pairs)):\n",
    "    qg.append([0]*len(rows))    #依据主题词不同改数字(类数)\n",
    "\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        for k in range(len(rows)):\n",
    "            if(len(y2['属性词'])!=0):\n",
    "                if(y2['属性词'][0] in rows[k]):\n",
    "                    if((len(y2['情感词'])!=0) or (len(y2['修饰词'])!=0)):\n",
    "                        qg[i][k]= qg[i][k]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5f1fbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = []    ##每句每一类累加情感值\n",
    "for i in range(len(emotion_pairs)):\n",
    "    value.append([0]*len(rows))\n",
    "    \n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        if(emotion_value[i][j]!=0):\n",
    "            if(len(y2['属性词'])!= 0):\n",
    "                for k in range(len(rows)):\n",
    "                    if(y2['属性词'][0] in rows[k]):\n",
    "                        if((len(y2['情感词'])!=0) or (len(y2['修饰词'])!=0)):\n",
    "                            if(qg[i][k]>0):\n",
    "                                value[i][k]=value[i][k]+emotion_value[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4bb25be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68287\n",
      "68287\n"
     ]
    }
   ],
   "source": [
    "print(len(qg))\n",
    "print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cf7e08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,y1 in enumerate(value):\n",
    "    for j,y2 in enumerate(y1):\n",
    "        if(y2!=0):\n",
    "            value[i][j]=float(('%.1f' % y2))    ##更改保留小数位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a20f83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_sort = [[],[],[],[],[],[],[]]\n",
    "for i in value:\n",
    "    value_sort[0].append(i[0])\n",
    "    value_sort[1].append(i[1])\n",
    "    value_sort[2].append(i[2])\n",
    "    value_sort[3].append(i[3])\n",
    "    value_sort[4].append(i[4])\n",
    "    value_sort[5].append(i[5])\n",
    "    value_sort[6].append(i[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0dc08849",
   "metadata": {},
   "outputs": [],
   "source": [
    "qg_sort = [[],[],[],[],[],[],[]]\n",
    "for i in qg:\n",
    "    qg_sort[0].append(i[0])\n",
    "    qg_sort[1].append(i[1])\n",
    "    qg_sort[2].append(i[2])\n",
    "    qg_sort[3].append(i[3])\n",
    "    qg_sort[4].append(i[4])\n",
    "    qg_sort[5].append(i[5])\n",
    "    qg_sort[6].append(i[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e997c06",
   "metadata": {},
   "source": [
    "## value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e9c2306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37584.79999999986, 4801.499999999969, 34553.89999999978, 55004.200000001, 10927.099999999982, 4461.10000000003, 998.5]\n",
      "148331.10000000062\n"
     ]
    }
   ],
   "source": [
    "v = [[],[],[],[],[],[],[]]\n",
    "for i in range(len(v)):\n",
    "    v[i] = sum(value_sort[i])\n",
    "print(v)\n",
    "print(sum(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf312f",
   "metadata": {},
   "source": [
    "## pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6db6e949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31335, 4907, 37979, 48631, 11242, 5764, 1281]\n",
      "141139\n"
     ]
    }
   ],
   "source": [
    "v1 = [[],[],[],[],[],[],[]]\n",
    "for i in range(len(v1)):\n",
    "    v1[i] = sum(qg_sort[i])\n",
    "print(v1)\n",
    "print(sum(v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0d9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e0bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d6b11f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07891636 0.61079366 0.78210344 0.09269898 0.02060156]]\n"
     ]
    }
   ],
   "source": [
    "v1 = [31335,4907,37979,48631,11242,5764,1281]\n",
    "del(v1[4])\n",
    "del(v1[0])\n",
    "v1 = [v1]\n",
    "v1_nor = preprocessing.normalize(v1, norm='l2')\n",
    "print(v1_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b24ab37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pop = [0.37555076,0.0487125,0.41356611,0.79363438,0.18078601,0.15108119,0.01368041]\n",
    "m_pop = [0.51349178,0.07025398,0.4719613,0.67658327,0.15278792,0.16527869,0.01473067]\n",
    "l_pop = [0.44427431,0.06957249,0.53847435,0.68950068,0.15939147,0.08172322,0.01816229]\n",
    "\n",
    "h_qg = [0.48238547,0.17325946,0.40842793,0.60587772,0.29808486,0.32822818,0.08243737]\n",
    "m_qg = [0.50634945,0.24922782,0.40886978,0.50535604,0.34457819,0.35924829,0.10556061]\n",
    "l_qg = [0.50454017,0.22878326,0.44996747,0.51033139,0.35635912,0.29376844,0.12998793]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ee251f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44427431 0.06957249 0.53847435 0.68950068 0.15939147 0.08172322\n",
      "  0.01816229]]\n"
     ]
    }
   ],
   "source": [
    "l_pop = [l_pop]\n",
    "l_qg = [l_qg]\n",
    "l_pop_nor = preprocessing.normalize(l_pop, norm='l2')\n",
    "l_qg_nor = preprocessing.normalize(l_qg, norm='l2')\n",
    "print(l_pop_nor)\n",
    "print(l_qg_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be06fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pop = [m_pop]\n",
    "m_qg = [m_qg]\n",
    "m_pop_nor = preprocessing.normalize(m_pop, norm='l2')\n",
    "m_qg_nor = preprocessing.normalize(m_qg, norm='l2')\n",
    "print(m_pop_nor)\n",
    "print(m_qg_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3892402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pop = [h_pop]\n",
    "h_qg = [h_qg]\n",
    "h_pop_nor = preprocessing.normalize(h_pop, norm='l2')\n",
    "h_qg_nor = preprocessing.normalize(h_qg, norm='l2')\n",
    "print(h_pop_nor)\n",
    "print(h_qg_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d5b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c3d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4747e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e0dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "hotel = []\n",
    "n = 0\n",
    "f = open(r'E:\\selectedBrandAllInfo.csv',encoding='utf-8')\n",
    "csv_read = csv.reader(f)\n",
    "for line in csv_read:\n",
    "    n += 1\n",
    "    hotel.append(line)\n",
    "f.close()\n",
    "print(len(hotel))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea10ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hotel, columns=['0', '1', 'hotelId','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c1b6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\13万筛选三元组\\修改\\content_13w.txt\", 'w',encoding='utf-8') as f:\n",
    "    for i in content:\n",
    "        f.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8abb96a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31044/3851198555.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memotion_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m391657\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m385119\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m928851\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m375079\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m430265\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m430270\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m467314\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m369688\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m482983\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m33587215\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m427874\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m53120643\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m369708\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m61840052\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m347308\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m347414\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mhigh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hotelId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mhigh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "high = []    \n",
    "middle = []   \n",
    "low = []\n",
    "\n",
    "for i,y1 in enumerate(emotion_pairs):\n",
    "    if(df.iloc[i][\"hotelId\"]==391657 or df.iloc[i][\"hotelId\"]==385119 or df.iloc[i][\"hotelId\"]==928851 or df.iloc[i][\"hotelId\"]==375079 or df.iloc[i][\"hotelId\"]==430265 or df.iloc[i][\"hotelId\"]==430270 or df.iloc[i][\"hotelId\"]==467314 or df.iloc[i][\"hotelId\"]==369688 or df.iloc[i][\"hotelId\"]==482983 or df.iloc[i][\"hotelId\"]==33587215 or df.iloc[i][\"hotelId\"]==427874 or df.iloc[i][\"hotelId\"]==53120643 or df.iloc[i][\"hotelId\"]==369708 or df.iloc[i][\"hotelId\"]==61840052 or df.iloc[i][\"hotelId\"]==347308 or df.iloc[i][\"hotelId\"]==347414):\n",
    "        al[i].append(hotel[3])\n",
    "        al[i].append(hotel[9])\n",
    "        high.append(al[i])\n",
    "    elif(df.iloc[i][\"hotelId\"]==430214 or df.iloc[i][\"hotelId\"]==427531 or df.iloc[i][\"hotelId\"]==430223 or df.iloc[i][\"hotelId\"]==747665 or df.iloc[i][\"hotelId\"]==430229 or df.iloc[i][\"hotelId\"]==980232 or df.iloc[i][\"hotelId\"]==46007521 or df.iloc[i][\"hotelId\"]==9619023 or df.iloc[i][\"hotelId\"]==63337143 or df.iloc[i][\"hotelId\"]==65394133 or df.iloc[i][\"hotelId\"]==9444856 or df.iloc[i][\"hotelId\"]==2272090 or df.iloc[i][\"hotelId\"]==48611068 or df.iloc[i][\"hotelId\"]==2231618 or df.iloc[i][\"hotelId\"]==763321 or df.iloc[i][\"hotelId\"]==11305146 or df.iloc[i][\"hotelId\"]==6589045 or df.iloc[i][\"hotelId\"]==65110141 or df.iloc[i][\"hotelId\"]==30006625 or df.iloc[i][\"hotelId\"]==12659788 or df.iloc[i][\"hotelId\"]==52159868 or df.iloc[i][\"hotelId\"]==32808664 or df.iloc[i][\"hotelId\"]==57019623 or df.iloc[i][\"hotelId\"]==60910621 or df.iloc[i][\"hotelId\"]==64226079 or df.iloc[i][\"hotelId\"]==1577568 or df.iloc[i][\"hotelId\"]==5754064 or df.iloc[i][\"hotelId\"]==5293044 or df.iloc[i][\"hotelId\"]==60976659 or df.iloc[i][\"hotelId\"]==37520955 or df.iloc[i][\"hotelId\"]==41648809):\n",
    "        low.append(al[i])\n",
    "    else:\n",
    "        middle.append(al[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30d6b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1.5, 1, 1.0, 2, 3.0, 2, 2.5, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(high[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af65222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data = []\n",
    "f = open(r'D:\\selectedBrandAllInfo.csv',encoding='utf-8')\n",
    "csv_read = csv.reader(f)\n",
    "index=0\n",
    "for line in csv_read:\n",
    "    if index != 0 :\n",
    "        data.append(fx[index-1][::-1]+zx[index-1][::-1])                \n",
    "        data[index-1].append(line[3])\n",
    "        data[index-1].append(line[2])\n",
    "        data[index-1].append(line[1])\n",
    "        data[index-1].append(line[0])\n",
    "    index+=1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=['hotelID','content','emotion_pairs','Factor1Count','Factor1Val','Factor2Count','Factor2Val','Factor3Count','Factor3Val','Factor4Count','Factor4Val','Factor5Count','Factor5Val']\n",
    "f = open(r'E:\\high_cot_val.csv','w',newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(rows)\n",
    "for l in high:\n",
    "    writer.writerow(l)   \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccbbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
